{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "40d72063-2687-4a72-a486-a1470da92a57",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "import h5py\n",
    "from exabiome.nn.loader import read_dataset, LazySeqDataset\n",
    "import argparse\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import torch.nn as nn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "aec0806b-6c0e-4b2d-9c15-57e6029bc5de",
   "metadata": {},
   "outputs": [],
   "source": [
    "path = '/global/homes/a/azaidi/ar122_r202.toy.input.h5'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d3906eea-a618-4a41-912e-f7044712abd3",
   "metadata": {},
   "outputs": [],
   "source": [
    "hparams = argparse.Namespace(**{'load': False,\n",
    "                            'window': 4096,\n",
    "                            'step': 4096,\n",
    "                             'classify': True,\n",
    "                               'tgt_tax_lvl': \"phylum\",\n",
    "                               'fwd_only': True})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d8c9e7b7-9f59-4008-b52c-b796e5c6389e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "19010"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chunks = LazySeqDataset(hparams, path=path, keep_open=True)\n",
    "len(chunks)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67741a8b-e7eb-4f79-9ddf-430b64a241d5",
   "metadata": {},
   "source": [
    "Let's use a function to use a transform for the x value (for padding) instead of having that logic in the dataset class "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "65b84139-7b46-4d6b-84c8-a410c9ae23b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def pad_seq(seq):\n",
    "    if(len(seq) < 4096):\n",
    "        padded = torch.zeros(4096)\n",
    "        padded[:len(seq)] = seq\n",
    "        return padded\n",
    "    else:\n",
    "        return seq"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81916c9c-98c7-407f-9a9b-8c6fd6e43785",
   "metadata": {},
   "source": [
    "That's not a very clean transform fxn above, but w/e -- Pytorch uses lambda functions in their docs anyways ;)\n",
    "\n",
    "We also don't want to do the unsqueezing at the batch level everytime it's called -- let's do it here :)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "876f2f59-8585-4a5e-a30e-c3bd6d62a96a",
   "metadata": {},
   "outputs": [],
   "source": [
    "class taxon_ds(Dataset):\n",
    "    def __init__(self, chunks, transform):\n",
    "        self.chunks = chunks\n",
    "        self.transform = transform\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.chunks)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        x = chunks[idx][1]\n",
    "        x = self.transform(x)\n",
    "        y = chunks[idx][2]\n",
    "        return (x.unsqueeze(0), y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "cad2b8dd-d5a0-41c5-8d74-e5bcb53b65b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "ds = taxon_ds(chunks, pad_seq)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "bc6fa684-ea9d-46cf-909b-a67fb6982352",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([1, 4096]), torch.Size([1, 4096]))"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ds[0][0].shape, ds[2][0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "25c2caa2-3655-4d1b-a2da-463d04a068f7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1189"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dl = DataLoader(ds, batch_size=16, shuffle=True)\n",
    "len(dl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "7d48d4f1-1c88-473a-8fd6-3f08ae71fbec",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([16, 1, 4096]), torch.Size([16]))"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch = next(iter(dl))\n",
    "batch[0].shape, batch[1].shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6bd2b07-4f2e-4b95-af80-875499b93a54",
   "metadata": {},
   "source": [
    "We'll use timm to take a look at what the efficientnet architecture looks like"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "4ed467f3-3335-4861-9988-db1d95e89755",
   "metadata": {},
   "outputs": [],
   "source": [
    "import timm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "aeb2fdb5-ea7b-47ab-96a4-116b0c2b3af2",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = timm.create_model('efficientnet_b0', pretrained=False, in_chans=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "d2086e40-1e87-41b0-b261-8b88270f315d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#uncomment below to see full arch\n",
    "#model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "9e2cb373-474e-4444-bf3d-62069c167eae",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Conv2d(1, 32, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.conv_stem"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "c9e9d0f0-ea4a-4d79-80e9-0ca4c04527f3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Sequential(\n",
       "  (0): DepthwiseSeparableConv(\n",
       "    (conv_dw): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False)\n",
       "    (bn1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (act1): SiLU(inplace=True)\n",
       "    (se): SqueezeExcite(\n",
       "      (conv_reduce): Conv2d(32, 8, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (act1): SiLU(inplace=True)\n",
       "      (conv_expand): Conv2d(8, 32, kernel_size=(1, 1), stride=(1, 1))\n",
       "    )\n",
       "    (conv_pw): Conv2d(32, 16, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "    (bn2): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (act2): Identity()\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.blocks[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a1f7cc5-ac40-416e-82a2-fc24ec12af72",
   "metadata": {},
   "source": [
    "looks like it should be a bunch of conv1d's -> batchnorm1d -> SiLU\n",
    "\n",
    "We'll make an arbitrary one below, just to test out that we can push the data through these types of layers -- the values inside of the layers are arbitrarily chosen (aside from first conv layer which needs to know that the input will have one channel)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "7cd876ac-4490-4f41-85fe-9c6e08db7fea",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = nn.Sequential(\n",
    "            nn.Conv1d(1, 32, kernel_size=3),\n",
    "            nn.BatchNorm1d(32),\n",
    "            nn.SiLU(inplace=True),\n",
    "            nn.Conv1d(32, 32, kernel_size=3),\n",
    "             nn.BatchNorm1d(32),\n",
    "             nn.SiLU(inplace=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "721ef3d3-65af-4142-8177-5bd6ec9bba7d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([16, 32, 4092])"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model(batch[0]).shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b08e822-2341-4236-8d08-814af60602f2",
   "metadata": {},
   "source": [
    "Looks like it should be straightforward enough, as expected :)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd1f00b4-3039-4903-a2c3-66e04a89d683",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "zenv",
   "language": "python",
   "name": "zenv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
