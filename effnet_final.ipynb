{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3d0a5049-ff45-442d-bdb8-17d455727af3",
   "metadata": {},
   "source": [
    "We should've used classes rather than functions to define our architecture.\n",
    "\n",
    "The residual connections were also missed before -- both improvements below"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6434cbf7-2895-4fe7-8f0d-98703acb33ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "from data import *\n",
    "from model import *\n",
    "\n",
    "import torch\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "import h5py\n",
    "from exabiome.nn.loader import read_dataset, LazySeqDataset, train_test_loaders\n",
    "import argparse\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import torch.nn as nn\n",
    "from typing import Type, Any, Callable, Union, List, Optional"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "id": "5608acfe-f012-4045-a59b-bbb177c28c70",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sat Jun 19 15:00:15 2021       \n",
      "+-----------------------------------------------------------------------------+\n",
      "| NVIDIA-SMI 450.102.04   Driver Version: 450.102.04   CUDA Version: 11.0     |\n",
      "|-------------------------------+----------------------+----------------------+\n",
      "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
      "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
      "|                               |                      |               MIG M. |\n",
      "|===============================+======================+======================|\n",
      "|   0  Tesla V100-SXM2...  On   | 00000000:1A:00.0 Off |                    0 |\n",
      "| N/A   34C    P0    64W / 300W |  13956MiB / 16160MiB |      0%      Default |\n",
      "|                               |                      |                  N/A |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "                                                                               \n",
      "+-----------------------------------------------------------------------------+\n",
      "| Processes:                                                                  |\n",
      "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
      "|        ID   ID                                                   Usage      |\n",
      "|=============================================================================|\n",
      "|    0   N/A  N/A     72238      C   ...onda/envs/zenv/bin/python    13953MiB |\n",
      "+-----------------------------------------------------------------------------+\n"
     ]
    }
   ],
   "source": [
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "681347d7-73ce-426c-a03c-b8dcc70a63ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "hparams = argparse.Namespace(**{'load': False,\n",
    "                            'window': 4096,\n",
    "                            'step': 4096,\n",
    "                             'classify': False,\n",
    "                               'tgt_tax_lvl': \"species\",\n",
    "                               'fwd_only': True,\n",
    "                               'manifold': True})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0c5760d6-5a4d-49ab-8fcf-51325e92599f",
   "metadata": {},
   "outputs": [],
   "source": [
    "path = '/global/homes/a/azaidi/ar122_r202.toy.input.h5'\n",
    "chunks = LazySeqDataset(hparams, path=path,\n",
    "                       keep_open=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "874f32da-d6d6-45e8-b2f6-8530dfd1832a",
   "metadata": {},
   "outputs": [],
   "source": [
    "dl0, dl1, dl2 = train_test_loaders(chunks, batch_size=16, distances=True)\n",
    "#batch = next(iter(dl2))\n",
    "#train_test_loaders??"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1ad1a061-e307-4f03-b9dc-aa970f342445",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_toy_dl(hparams, batch_size=16):\n",
    "    path = '/global/homes/a/azaidi/ar122_r202.toy.input.h5'\n",
    "    chunks = LazySeqDataset(hparams, path=path,\n",
    "                           keep_open=True)\n",
    "    ds = taxon_ds(chunks, old_pad_seq)\n",
    "    return DataLoader(ds, batch_size=batch_size, \n",
    "                      shuffle=True), ds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4b2497a2-a52e-45f2-b678-8dad2ae9ac47",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2377, torch.Size([8, 1, 4096]), torch.Size([8]))"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dl,ds = get_toy_dl(hparams, batch_size=8)\n",
    "batch = next(iter(dl))\n",
    "len(dl)\n",
    ", batch[0].shape, batch[1].shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1404e3fa-a9fb-428e-9ff0-b00930f90ecf",
   "metadata": {},
   "source": [
    "Let's creat a block class that we'll use for the inverted residual blocks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "75591930-8754-4801-910e-64c0befe0a14",
   "metadata": {},
   "outputs": [],
   "source": [
    "class DepSepBlock(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(DepSepBlock, self).__init__()\n",
    "        self.conv1 = nn.Conv1d(32, 32, 3)\n",
    "        self.bn1 = nn.BatchNorm1d(32)\n",
    "        self.act = nn.SiLU(inplace=True)\n",
    "        self.conv2 = nn.Conv1d(32, 8, 1)\n",
    "        self.conv3 = nn.Conv1d(8, 32, 1)\n",
    "        self.conv4 = nn.Conv1d(32, 16, 1, stride=1)\n",
    "        self.bn2 = nn.BatchNorm1d(16)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        identity = x\n",
    "        \n",
    "        out = self.conv1(x)\n",
    "        out = self.bn1(out)\n",
    "        out = self.act(out)\n",
    "        out = self.conv2(out)\n",
    "        out = self.act(out)\n",
    "        out = self.conv3(out)\n",
    "        out = self.conv4(out)\n",
    "        out = self.bn2(out)\n",
    "        #out = nn.Identity(out)\n",
    "        \n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "3785c8b3-bb68-43b0-a784-9f37be779907",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([8, 32, 2048])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dsc_out = nn.Conv1d(1, 32, kernel_size=3, stride=2, padding=1)(batch[0])\n",
    "dsc_out.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "522da7c7-81ad-4fd2-a5c2-904d02ed62df",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([8, 16, 2046])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "DepSepBlock()(dsc_out).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "838d8a4a-6be1-4f8b-8ed6-f4a4f12ca9f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "class InvertedResidualBlock(nn.Module):\n",
    "    def __init__(self, in_ch:int, mid_ch:int, sq_ch:int,\n",
    "                 out_ch:int, ks=1, stride: int = 1, padding: int =0):\n",
    "        super(InvertedResidualBlock, self).__init__()\n",
    "        \n",
    "        self.conv1 = nn.Conv1d(in_ch, mid_ch, kernel_size=1, stride=1)\n",
    "        self.bn1 = nn.BatchNorm1d(mid_ch)\n",
    "        self.act = nn.SiLU(inplace=True)\n",
    "        self.conv2 = nn.Conv1d(mid_ch, mid_ch, kernel_size=ks, stride=stride,\n",
    "                              padding=padding)\n",
    "        self.bn2 = nn.BatchNorm1d(mid_ch)\n",
    "        #self.conv3 = nn.Conv1d(mid_ch, sq_ch, kernel_size=1,\n",
    "        #                      stride=1) #squeeze excite conv\n",
    "        #self.conv4 = nn.Conv1d(sq_ch, mid_ch, kernel_size=1,\n",
    "        #                      stride=1) #squeeze excite conv\n",
    "        self.squeeze = SqueezeExcite(mid_ch, sq_ch)\n",
    "        self.conv5 = nn.Conv1d(mid_ch, out_ch, kernel_size=1, stride=1) \n",
    "        self.bn3 = nn.BatchNorm1d(out_ch)\n",
    "        \n",
    "        self.downsample = nn.Conv1d(in_ch, out_ch,1, stride=stride)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        identity = x\n",
    "        \n",
    "        out = self.conv1(x)\n",
    "        out = self.bn1(out)\n",
    "        out = self.act(out)\n",
    "        out = self.conv2(out)\n",
    "        out = self.bn2(out)\n",
    "        #out = self.conv3(out)\n",
    "        #out = self.act(out)\n",
    "        #out = self.conv4(out)\n",
    "        out = self.squeeze(out)\n",
    "        out = self.conv5(out)\n",
    "        out = self.bn3(out)\n",
    "        \n",
    "        identity = self.downsample(x)\n",
    "        out += identity\n",
    "        out = self.act(out)\n",
    "        \n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "8a3cd349-49fa-4a46-8322-be75a680df42",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "InvertedResidualBlock(\n",
       "  (conv1): Conv1d(1, 5, kernel_size=(1,), stride=(1,))\n",
       "  (bn1): BatchNorm1d(5, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (act): SiLU(inplace=True)\n",
       "  (conv2): Conv1d(5, 5, kernel_size=(5,), stride=(2,), padding=(2,))\n",
       "  (bn2): BatchNorm1d(5, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (squeeze): SqueezeExcite(\n",
       "    (layer): Sequential(\n",
       "      (0): Conv1d(5, 3, kernel_size=(1,), stride=(1,))\n",
       "      (1): SiLU(inplace=True)\n",
       "      (2): Conv1d(3, 5, kernel_size=(1,), stride=(1,))\n",
       "    )\n",
       "  )\n",
       "  (conv5): Conv1d(5, 6, kernel_size=(1,), stride=(1,))\n",
       "  (bn3): BatchNorm1d(6, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (downsample): Conv1d(1, 6, kernel_size=(1,), stride=(2,))\n",
       ")"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "irb = InvertedResidualBlock(1, 5, 3, 6, 5, 2,2)\n",
    "irb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "46824b58-8104-4f05-b07b-ae3df750bafe",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([8, 6, 2048])"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "irb(batch[0]).shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2de5731-1839-4c42-a5b5-4da287486ce6",
   "metadata": {},
   "source": [
    "Using the class below makes our model description look terrible -- so we'll keep this out of the model definition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "0d58601c-da2c-4d63-9352-25cbb719b8b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ConvBnAct(nn.Module):\n",
    "    def __init__(self, in_ch, out_ch, ks=1, stride=1, padding=0, activation=False):\n",
    "        super().__init__()\n",
    "        layer_list = []\n",
    "        layer_list.append(nn.Conv1d(in_ch, out_ch,\n",
    "                                   kernel_size=ks, stride=stride,\n",
    "                                   padding=padding))\n",
    "        layer_list.append(nn.BatchNorm1d(out_ch))\n",
    "        if activation:\n",
    "            layer_list.append(nn.SiLU(inplace=True))\n",
    "        self.layer_list = nn.Sequential(*layer_list)\n",
    "    def forward(self, x):\n",
    "        out = self.layer_list(x)\n",
    "        return out + x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "eb0a63bb-7401-4863-b207-5af8a8608276",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ConvBnAct(\n",
       "  (layer_list): Sequential(\n",
       "    (0): Conv1d(1, 5, kernel_size=(1,), stride=(1,))\n",
       "    (1): BatchNorm1d(5, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): SiLU(inplace=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ConvBnAct(1, 5, activation=True)#(batch[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "4ab70ceb-d95b-4247-920c-25e2160d5b97",
   "metadata": {},
   "outputs": [],
   "source": [
    "class InvertedResidualBlock(nn.Module):\n",
    "    def __init__(self, in_ch:int, mid_ch:int, sq_ch:int,\n",
    "                 out_ch:int, ks=1, stride: int = 1, padding: int =0):\n",
    "        super(InvertedResidualBlock, self).__init__()\n",
    "        \n",
    "        self.conv1 = ConvBnAct(in_ch, mid_ch, activation=True)\n",
    "        self.conv2 = ConvBnAct(mid_ch, mid_ch, ks=ks, stride=stride, padding=padding)\n",
    "        #self.squeeze = SqueezeExcite(mid_ch, sq_ch)\n",
    "        self.conv3 = ConvBnAct(mid_ch, out_ch)\n",
    "\n",
    "        self.downsample = nn.Conv1d(in_ch, out_ch,1, stride=stride)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        identity = x\n",
    "        \n",
    "        out = self.conv1(x)\n",
    "        out = self.conv2(out)\n",
    "        out = self.squeeze(out)\n",
    "        out = self.conv3(out)\n",
    "        \n",
    "        identity = self.downsample(x)\n",
    "        out += identity\n",
    "        \n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "id": "699934e2-2a3c-4264-a288-e36ed63eb64b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#uncomment to confirm this does not look like what we want\n",
    "#InvertedResidualBlock(1, 6, 8, 20)#(batch[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0dbd220b-1a29-4355-a560-74c64f14ef52",
   "metadata": {},
   "source": [
    "We can wrap the squeeze excite up into it's own class though, similar to how it's done in Timm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "9e7c5de9-3ad5-4436-9214-2e70def0760b",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SqueezeExcite(nn.Module):\n",
    "    def __init__(self, ch_in, mid_ch):\n",
    "        super().__init__()\n",
    "        self.layer = nn.Sequential(\n",
    "            nn.Conv1d(ch_in, mid_ch, kernel_size=1, stride=1),\n",
    "            nn.SiLU(inplace=True),\n",
    "            nn.Conv1d(mid_ch, ch_in, kernel_size=1, stride=1)\n",
    "        )\n",
    "    def forward(self, x):\n",
    "        out = self.layer(x)\n",
    "        return out + x"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d43edbfd-0542-4ff6-a98c-3fe6e2238691",
   "metadata": {},
   "source": [
    "Here's our final version of the inverted residual block"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "id": "22e7c67d-0a00-43e4-a468-ccc7a6dfd0bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "class InvertedResidualBlock(nn.Module):\n",
    "    def __init__(self, in_ch:int, mid_ch:int, sq_ch:int,\n",
    "                 out_ch:int, ks=1, stride: int = 1, padding: int =0):\n",
    "        super(InvertedResidualBlock, self).__init__()\n",
    "        \n",
    "        self.conv1 = nn.Conv1d(in_ch, mid_ch, kernel_size=1, stride=1)\n",
    "        self.bn1 = nn.BatchNorm1d(mid_ch)\n",
    "        self.act = nn.SiLU(inplace=True)\n",
    "        self.conv2 = nn.Conv1d(mid_ch, mid_ch, kernel_size=ks, stride=stride,\n",
    "                              padding=padding)\n",
    "        self.bn2 = nn.BatchNorm1d(mid_ch)\n",
    "        self.squeeze = SqueezeExcite(mid_ch, sq_ch)\n",
    "        self.conv5 = nn.Conv1d(mid_ch, out_ch, kernel_size=1, stride=1) \n",
    "        self.bn3 = nn.BatchNorm1d(out_ch)\n",
    "        \n",
    "        self.downsample = nn.Conv1d(in_ch, out_ch,1, stride=stride)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        identity = x\n",
    "        \n",
    "        out = self.conv1(x)\n",
    "        out = self.bn1(out)\n",
    "        out = self.act(out)\n",
    "        out = self.conv2(out)\n",
    "        out = self.bn2(out)\n",
    "        out = self.squeeze(out)\n",
    "        out = self.conv5(out)\n",
    "        out = self.bn3(out)\n",
    "        \n",
    "        identity = self.downsample(x)\n",
    "        out += identity\n",
    "        out = self.act(out)\n",
    "        \n",
    "        return out"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "119c6eb2-8804-4b91-82ca-720488a1a174",
   "metadata": {},
   "source": [
    "Let's also incoroprate a make layer function that will "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "id": "a6ab3796-0ba9-4f29-961d-9a093e4e7084",
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_layer(param_list):\n",
    "    layers = []\n",
    "    for x in range(len(param_list)):\n",
    "        layers.append(InvertedResidualBlock(*param_list[x]))\n",
    "    return nn.Sequential(*layers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "id": "7ce81a1c-dd21-405a-83e5-477b51cba076",
   "metadata": {},
   "outputs": [],
   "source": [
    "ll = []\n",
    "for x in range(len(p_list)):\n",
    "    ll.append(make_layer(param_list = p_list[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "id": "63a91e24-3602-40ae-9fe9-f0880e40aec4",
   "metadata": {},
   "outputs": [],
   "source": [
    "#uncomment below to confirm this is doing what is desired\n",
    "#ll"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d19ac29-f6a8-465e-8195-19c3535323d1",
   "metadata": {},
   "source": [
    "Previously our model definition had us explicitly calling each layer group and then having to pass them one by one in the forward implementation. With the layer list function above, we can clean up our model definition!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "id": "4c0b0b26-75df-413c-83f9-c628c4e4b8a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "class TestNet(nn.Module):\n",
    "    def __init__(self, param_list, avg_out=200, out_feats=512):\n",
    "        super(TestNet, self).__init__()\n",
    "\n",
    "        self.avg_out = 18\n",
    "        self.out_feats = out_feats\n",
    "        self.param_list = param_list\n",
    "\n",
    "        self.conv1 = nn.Conv1d(1, 32, kernel_size=3, stride=2, padding=1)\n",
    "        self.bn1 = nn.BatchNorm1d(32)\n",
    "        self.silu = nn.SiLU(inplace=True)\n",
    "        self.layer0 = DepSepBlock()\n",
    "        self.layer_list = []\n",
    "        for x in range(len(p_list)):\n",
    "            self.layer_list.append(self._make_layer(self.param_list[x]))\n",
    "        self.layer_list = nn.Sequential(*self.layer_list)\n",
    "        self.conv2 = nn.Conv1d(320, 18, 1, 1)\n",
    "        self.bn2 = nn.BatchNorm1d(18)\n",
    "        self.avgpool = nn.AdaptiveAvgPool1d(output_size=self.avg_out)\n",
    "        self.fc = nn.Linear(in_features=self.avg_out, \n",
    "                            out_features=self.out_feats)\n",
    "    \n",
    "    def _make_layer(self, param_list):\n",
    "        layers = []\n",
    "        for x in range(len(param_list)):\n",
    "            layers.append(InvertedResidualBlock(*param_list[x]))\n",
    "        return nn.Sequential(*layers)\n",
    "        \n",
    "    def _forward_impl(self, x):\n",
    "        x = self.conv1(x)\n",
    "        x = self.bn1(x)\n",
    "        x = self.silu(x)\n",
    "        \n",
    "        x = self.layer0(x)\n",
    "        x = self.layer_list(x)\n",
    "        x = self.conv2(x)\n",
    "        x = self.bn2(x)\n",
    "        x = self.avgpool(x)\n",
    "        x = self.fc(x)\n",
    "        return x\n",
    "    \n",
    "    def forward(self, x):\n",
    "        return self._forward_impl(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca6d0bea-dcf0-413e-80f5-16cb34e990b1",
   "metadata": {},
   "source": [
    "Unfortunately, we are still hardcoding the values into our model definition, w/e"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "id": "177fdea3-cb29-45de-adf8-e87901527a55",
   "metadata": {},
   "outputs": [],
   "source": [
    "p_list = [\n",
    "        [[16,96,3,24,3,2,1], [24,144,6,24,3,1,1]], #layer 1\n",
    "        [[24,144,6,40,5,2,2], [40,240,10,40,5,1,2]], #layer 2 \n",
    "        [[40,240,10,80,3,2,1],[80,480,20,80,3,1,1], \n",
    "                                [80,480,20,80,3,1,1]], #layer 3\n",
    "        [[80,480,20,112,5,1,2], [112,672,28,112,5,1,2], \n",
    "                                 [112,672,28,112,5,1,2]], #layer 4\n",
    "        [[112,672,28,192,5,2,2],[192,1152,48,192,5,1,2],\n",
    "         [192,1152,48,192,5,1,2], [192,1152,48,192,5,1,2]], #layer 5\n",
    "        [[192,1152,48,320,3,2,1]] #layer 6\n",
    "         ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "id": "2a048577-fe62-4efc-895f-7acbb5367d65",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([8, 18, 1])"
      ]
     },
     "execution_count": 158,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m = TestNet(p_list, out_feats=1, avg_out=18)\n",
    "#m\n",
    "m(batch[0]).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "id": "26a49b50-a5eb-433b-b8ea-0eea887d4faf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([8, 1280, 512])"
      ]
     },
     "execution_count": 144,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "out = TestNet(p_list)(batch[0])\n",
    "out.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "047b0ea1-25c5-474d-a534-37ae5bfe2670",
   "metadata": {},
   "source": [
    "The above cell confirms that our model can complete a forward pass -- the below cell shows our previous (disgusting) definition of the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "id": "63f82f7e-205c-4bf9-9a3b-6e950cfa8396",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_eff_b0(out_feats):\n",
    "    return nn.Sequential(\n",
    "        get_base_layer(),\n",
    "        get_dep_sep(32, 16),\n",
    "\n",
    "        #layer 1 has two inverted residuals (IRs)\n",
    "        get_inv_res(in_ch=16, mid_ch=96, out_ch=24,\n",
    "                   sq_ch=4, ks=3, stride=2, padding=1),\n",
    "        get_inv_res(in_ch=24, mid_ch=144, out_ch=24,\n",
    "                   sq_ch=6, ks=3, stride=1, padding=1),\n",
    "\n",
    "        #layers 2 has 2 IR's\n",
    "        get_inv_res(in_ch=24, mid_ch=144, out_ch=40,\n",
    "                   sq_ch=6, ks=5, stride=2, padding=2),\n",
    "        get_inv_res(in_ch=40, mid_ch=240, out_ch=40,\n",
    "                   sq_ch=10, ks=5, stride=2, padding=2),\n",
    "\n",
    "        #layer 3 has 3 IR's\n",
    "        get_inv_res(in_ch=40, mid_ch=240, out_ch=80,\n",
    "                   sq_ch=10, ks=3, stride=2, padding=1),\n",
    "        get_inv_res(in_ch=80, mid_ch=480, out_ch=80,\n",
    "                   sq_ch=20, ks=3, stride=1, padding=1),\n",
    "        get_inv_res(in_ch=80, mid_ch=480, out_ch=80,\n",
    "                   sq_ch=20, ks=3, stride=1, padding=1),\n",
    "\n",
    "        #layer 4 has 3 inverted residuals\n",
    "        get_inv_res(in_ch=80, mid_ch=480, out_ch=112,\n",
    "                   sq_ch=20, ks=5, stride=1, padding=2),\n",
    "        get_inv_res(in_ch=112, mid_ch=672, out_ch=112,\n",
    "                   sq_ch=28, ks=5, stride=1, padding=2),\n",
    "        get_inv_res(in_ch=112, mid_ch=672, out_ch=112,\n",
    "                   sq_ch=28, ks=5, stride=1, padding=2),\n",
    "\n",
    "        #layer 5 has 4 inverted residuals\n",
    "        get_inv_res(in_ch=112, mid_ch=672, out_ch=192,\n",
    "                   sq_ch=28, ks=5, stride=2, padding=2),\n",
    "        get_inv_res(in_ch=192, mid_ch=1152, out_ch=192,\n",
    "                   sq_ch=48, ks=5, stride=1, padding=2),\n",
    "        get_inv_res(in_ch=192, mid_ch=1152, out_ch=192,\n",
    "                   sq_ch=48, ks=5, stride=1, padding=2),\n",
    "        get_inv_res(in_ch=192, mid_ch=1152, out_ch=192,\n",
    "                   sq_ch=48, ks=5, stride=1, padding=2),\n",
    "        #layer 6 has 1 IR\n",
    "        get_inv_res(in_ch=192, mid_ch=1152, out_ch=320,\n",
    "                   sq_ch=48, ks=3, stride=1, padding=1),\n",
    "\n",
    "        get_head_layer(out_chans=out_feats)\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "id": "7391f6c1-b892-4ae2-8656-1f8c10772db3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([8, 18, 1])"
      ]
     },
     "execution_count": 160,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_eff_b0(18)(batch[0]).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "58b51fcb-7240-4688-b6a9-73c82479af42",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Sequential(\n",
       "  (0): Sequential(\n",
       "    (0): Sequential(\n",
       "      (0): Conv1d(1, 32, kernel_size=(3,), stride=(2,), padding=(1,), bias=False)\n",
       "      (1): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (1): SiLU(inplace=True)\n",
       "  )\n",
       "  (1): Sequential(\n",
       "    (0): Sequential(\n",
       "      (0): Sequential(\n",
       "        (0): Conv1d(32, 32, kernel_size=(3,), stride=(1,), bias=False)\n",
       "        (1): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (1): SiLU(inplace=True)\n",
       "    )\n",
       "    (1): Sequential(\n",
       "      (0): Conv1d(32, 8, kernel_size=(2,), stride=(2,))\n",
       "      (1): SiLU()\n",
       "      (2): Conv1d(8, 32, kernel_size=(2,), stride=(2,))\n",
       "    )\n",
       "    (2): Sequential(\n",
       "      (0): Conv1d(32, 16, kernel_size=(1,), stride=(1,), bias=False)\n",
       "      (1): BatchNorm1d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (3): Identity()\n",
       "  )\n",
       "  (2): Sequential(\n",
       "    (0): Sequential(\n",
       "      (0): Sequential(\n",
       "        (0): Conv1d(16, 96, kernel_size=(1,), stride=(1,), bias=False)\n",
       "        (1): BatchNorm1d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (1): SiLU(inplace=True)\n",
       "    )\n",
       "    (1): Sequential(\n",
       "      (0): Sequential(\n",
       "        (0): Conv1d(96, 96, kernel_size=(3,), stride=(2,), padding=(1,), bias=False)\n",
       "        (1): BatchNorm1d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (1): SiLU(inplace=True)\n",
       "    )\n",
       "    (2): Sequential(\n",
       "      (0): Conv1d(96, 4, kernel_size=(1,), stride=(1,))\n",
       "      (1): SiLU()\n",
       "      (2): Conv1d(4, 96, kernel_size=(1,), stride=(1,))\n",
       "    )\n",
       "    (3): Sequential(\n",
       "      (0): Conv1d(96, 24, kernel_size=(1,), stride=(1,), bias=False)\n",
       "      (1): BatchNorm1d(24, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "  )\n",
       "  (3): Sequential(\n",
       "    (0): Sequential(\n",
       "      (0): Sequential(\n",
       "        (0): Conv1d(24, 144, kernel_size=(1,), stride=(1,), bias=False)\n",
       "        (1): BatchNorm1d(144, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (1): SiLU(inplace=True)\n",
       "    )\n",
       "    (1): Sequential(\n",
       "      (0): Sequential(\n",
       "        (0): Conv1d(144, 144, kernel_size=(3,), stride=(1,), padding=(1,), bias=False)\n",
       "        (1): BatchNorm1d(144, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (1): SiLU(inplace=True)\n",
       "    )\n",
       "    (2): Sequential(\n",
       "      (0): Conv1d(144, 6, kernel_size=(1,), stride=(1,))\n",
       "      (1): SiLU()\n",
       "      (2): Conv1d(6, 144, kernel_size=(1,), stride=(1,))\n",
       "    )\n",
       "    (3): Sequential(\n",
       "      (0): Conv1d(144, 24, kernel_size=(1,), stride=(1,), bias=False)\n",
       "      (1): BatchNorm1d(24, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "  )\n",
       "  (4): Sequential(\n",
       "    (0): Sequential(\n",
       "      (0): Sequential(\n",
       "        (0): Conv1d(24, 144, kernel_size=(1,), stride=(1,), bias=False)\n",
       "        (1): BatchNorm1d(144, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (1): SiLU(inplace=True)\n",
       "    )\n",
       "    (1): Sequential(\n",
       "      (0): Sequential(\n",
       "        (0): Conv1d(144, 144, kernel_size=(5,), stride=(2,), padding=(2,), bias=False)\n",
       "        (1): BatchNorm1d(144, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (1): SiLU(inplace=True)\n",
       "    )\n",
       "    (2): Sequential(\n",
       "      (0): Conv1d(144, 6, kernel_size=(1,), stride=(1,))\n",
       "      (1): SiLU()\n",
       "      (2): Conv1d(6, 144, kernel_size=(1,), stride=(1,))\n",
       "    )\n",
       "    (3): Sequential(\n",
       "      (0): Conv1d(144, 40, kernel_size=(1,), stride=(1,), bias=False)\n",
       "      (1): BatchNorm1d(40, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "  )\n",
       "  (5): Sequential(\n",
       "    (0): Sequential(\n",
       "      (0): Sequential(\n",
       "        (0): Conv1d(40, 240, kernel_size=(1,), stride=(1,), bias=False)\n",
       "        (1): BatchNorm1d(240, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (1): SiLU(inplace=True)\n",
       "    )\n",
       "    (1): Sequential(\n",
       "      (0): Sequential(\n",
       "        (0): Conv1d(240, 240, kernel_size=(5,), stride=(2,), padding=(2,), bias=False)\n",
       "        (1): BatchNorm1d(240, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (1): SiLU(inplace=True)\n",
       "    )\n",
       "    (2): Sequential(\n",
       "      (0): Conv1d(240, 10, kernel_size=(1,), stride=(1,))\n",
       "      (1): SiLU()\n",
       "      (2): Conv1d(10, 240, kernel_size=(1,), stride=(1,))\n",
       "    )\n",
       "    (3): Sequential(\n",
       "      (0): Conv1d(240, 40, kernel_size=(1,), stride=(1,), bias=False)\n",
       "      (1): BatchNorm1d(40, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "  )\n",
       "  (6): Sequential(\n",
       "    (0): Sequential(\n",
       "      (0): Sequential(\n",
       "        (0): Conv1d(40, 240, kernel_size=(1,), stride=(1,), bias=False)\n",
       "        (1): BatchNorm1d(240, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (1): SiLU(inplace=True)\n",
       "    )\n",
       "    (1): Sequential(\n",
       "      (0): Sequential(\n",
       "        (0): Conv1d(240, 240, kernel_size=(3,), stride=(2,), padding=(1,), bias=False)\n",
       "        (1): BatchNorm1d(240, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (1): SiLU(inplace=True)\n",
       "    )\n",
       "    (2): Sequential(\n",
       "      (0): Conv1d(240, 10, kernel_size=(1,), stride=(1,))\n",
       "      (1): SiLU()\n",
       "      (2): Conv1d(10, 240, kernel_size=(1,), stride=(1,))\n",
       "    )\n",
       "    (3): Sequential(\n",
       "      (0): Conv1d(240, 80, kernel_size=(1,), stride=(1,), bias=False)\n",
       "      (1): BatchNorm1d(80, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "  )\n",
       "  (7): Sequential(\n",
       "    (0): Sequential(\n",
       "      (0): Sequential(\n",
       "        (0): Conv1d(80, 480, kernel_size=(1,), stride=(1,), bias=False)\n",
       "        (1): BatchNorm1d(480, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (1): SiLU(inplace=True)\n",
       "    )\n",
       "    (1): Sequential(\n",
       "      (0): Sequential(\n",
       "        (0): Conv1d(480, 480, kernel_size=(3,), stride=(1,), padding=(1,), bias=False)\n",
       "        (1): BatchNorm1d(480, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (1): SiLU(inplace=True)\n",
       "    )\n",
       "    (2): Sequential(\n",
       "      (0): Conv1d(480, 20, kernel_size=(1,), stride=(1,))\n",
       "      (1): SiLU()\n",
       "      (2): Conv1d(20, 480, kernel_size=(1,), stride=(1,))\n",
       "    )\n",
       "    (3): Sequential(\n",
       "      (0): Conv1d(480, 80, kernel_size=(1,), stride=(1,), bias=False)\n",
       "      (1): BatchNorm1d(80, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "  )\n",
       "  (8): Sequential(\n",
       "    (0): Sequential(\n",
       "      (0): Sequential(\n",
       "        (0): Conv1d(80, 480, kernel_size=(1,), stride=(1,), bias=False)\n",
       "        (1): BatchNorm1d(480, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (1): SiLU(inplace=True)\n",
       "    )\n",
       "    (1): Sequential(\n",
       "      (0): Sequential(\n",
       "        (0): Conv1d(480, 480, kernel_size=(3,), stride=(1,), padding=(1,), bias=False)\n",
       "        (1): BatchNorm1d(480, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (1): SiLU(inplace=True)\n",
       "    )\n",
       "    (2): Sequential(\n",
       "      (0): Conv1d(480, 20, kernel_size=(1,), stride=(1,))\n",
       "      (1): SiLU()\n",
       "      (2): Conv1d(20, 480, kernel_size=(1,), stride=(1,))\n",
       "    )\n",
       "    (3): Sequential(\n",
       "      (0): Conv1d(480, 80, kernel_size=(1,), stride=(1,), bias=False)\n",
       "      (1): BatchNorm1d(80, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "  )\n",
       "  (9): Sequential(\n",
       "    (0): Sequential(\n",
       "      (0): Sequential(\n",
       "        (0): Conv1d(80, 480, kernel_size=(1,), stride=(1,), bias=False)\n",
       "        (1): BatchNorm1d(480, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (1): SiLU(inplace=True)\n",
       "    )\n",
       "    (1): Sequential(\n",
       "      (0): Sequential(\n",
       "        (0): Conv1d(480, 480, kernel_size=(5,), stride=(1,), padding=(2,), bias=False)\n",
       "        (1): BatchNorm1d(480, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (1): SiLU(inplace=True)\n",
       "    )\n",
       "    (2): Sequential(\n",
       "      (0): Conv1d(480, 20, kernel_size=(1,), stride=(1,))\n",
       "      (1): SiLU()\n",
       "      (2): Conv1d(20, 480, kernel_size=(1,), stride=(1,))\n",
       "    )\n",
       "    (3): Sequential(\n",
       "      (0): Conv1d(480, 112, kernel_size=(1,), stride=(1,), bias=False)\n",
       "      (1): BatchNorm1d(112, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "  )\n",
       "  (10): Sequential(\n",
       "    (0): Sequential(\n",
       "      (0): Sequential(\n",
       "        (0): Conv1d(112, 672, kernel_size=(1,), stride=(1,), bias=False)\n",
       "        (1): BatchNorm1d(672, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (1): SiLU(inplace=True)\n",
       "    )\n",
       "    (1): Sequential(\n",
       "      (0): Sequential(\n",
       "        (0): Conv1d(672, 672, kernel_size=(5,), stride=(1,), padding=(2,), bias=False)\n",
       "        (1): BatchNorm1d(672, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (1): SiLU(inplace=True)\n",
       "    )\n",
       "    (2): Sequential(\n",
       "      (0): Conv1d(672, 28, kernel_size=(1,), stride=(1,))\n",
       "      (1): SiLU()\n",
       "      (2): Conv1d(28, 672, kernel_size=(1,), stride=(1,))\n",
       "    )\n",
       "    (3): Sequential(\n",
       "      (0): Conv1d(672, 112, kernel_size=(1,), stride=(1,), bias=False)\n",
       "      (1): BatchNorm1d(112, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "  )\n",
       "  (11): Sequential(\n",
       "    (0): Sequential(\n",
       "      (0): Sequential(\n",
       "        (0): Conv1d(112, 672, kernel_size=(1,), stride=(1,), bias=False)\n",
       "        (1): BatchNorm1d(672, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (1): SiLU(inplace=True)\n",
       "    )\n",
       "    (1): Sequential(\n",
       "      (0): Sequential(\n",
       "        (0): Conv1d(672, 672, kernel_size=(5,), stride=(1,), padding=(2,), bias=False)\n",
       "        (1): BatchNorm1d(672, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (1): SiLU(inplace=True)\n",
       "    )\n",
       "    (2): Sequential(\n",
       "      (0): Conv1d(672, 28, kernel_size=(1,), stride=(1,))\n",
       "      (1): SiLU()\n",
       "      (2): Conv1d(28, 672, kernel_size=(1,), stride=(1,))\n",
       "    )\n",
       "    (3): Sequential(\n",
       "      (0): Conv1d(672, 112, kernel_size=(1,), stride=(1,), bias=False)\n",
       "      (1): BatchNorm1d(112, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "  )\n",
       "  (12): Sequential(\n",
       "    (0): Sequential(\n",
       "      (0): Sequential(\n",
       "        (0): Conv1d(112, 672, kernel_size=(1,), stride=(1,), bias=False)\n",
       "        (1): BatchNorm1d(672, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (1): SiLU(inplace=True)\n",
       "    )\n",
       "    (1): Sequential(\n",
       "      (0): Sequential(\n",
       "        (0): Conv1d(672, 672, kernel_size=(5,), stride=(2,), padding=(2,), bias=False)\n",
       "        (1): BatchNorm1d(672, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (1): SiLU(inplace=True)\n",
       "    )\n",
       "    (2): Sequential(\n",
       "      (0): Conv1d(672, 28, kernel_size=(1,), stride=(1,))\n",
       "      (1): SiLU()\n",
       "      (2): Conv1d(28, 672, kernel_size=(1,), stride=(1,))\n",
       "    )\n",
       "    (3): Sequential(\n",
       "      (0): Conv1d(672, 192, kernel_size=(1,), stride=(1,), bias=False)\n",
       "      (1): BatchNorm1d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "  )\n",
       "  (13): Sequential(\n",
       "    (0): Sequential(\n",
       "      (0): Sequential(\n",
       "        (0): Conv1d(192, 1152, kernel_size=(1,), stride=(1,), bias=False)\n",
       "        (1): BatchNorm1d(1152, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (1): SiLU(inplace=True)\n",
       "    )\n",
       "    (1): Sequential(\n",
       "      (0): Sequential(\n",
       "        (0): Conv1d(1152, 1152, kernel_size=(5,), stride=(1,), padding=(2,), bias=False)\n",
       "        (1): BatchNorm1d(1152, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (1): SiLU(inplace=True)\n",
       "    )\n",
       "    (2): Sequential(\n",
       "      (0): Conv1d(1152, 48, kernel_size=(1,), stride=(1,))\n",
       "      (1): SiLU()\n",
       "      (2): Conv1d(48, 1152, kernel_size=(1,), stride=(1,))\n",
       "    )\n",
       "    (3): Sequential(\n",
       "      (0): Conv1d(1152, 192, kernel_size=(1,), stride=(1,), bias=False)\n",
       "      (1): BatchNorm1d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "  )\n",
       "  (14): Sequential(\n",
       "    (0): Sequential(\n",
       "      (0): Sequential(\n",
       "        (0): Conv1d(192, 1152, kernel_size=(1,), stride=(1,), bias=False)\n",
       "        (1): BatchNorm1d(1152, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (1): SiLU(inplace=True)\n",
       "    )\n",
       "    (1): Sequential(\n",
       "      (0): Sequential(\n",
       "        (0): Conv1d(1152, 1152, kernel_size=(5,), stride=(1,), padding=(2,), bias=False)\n",
       "        (1): BatchNorm1d(1152, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (1): SiLU(inplace=True)\n",
       "    )\n",
       "    (2): Sequential(\n",
       "      (0): Conv1d(1152, 48, kernel_size=(1,), stride=(1,))\n",
       "      (1): SiLU()\n",
       "      (2): Conv1d(48, 1152, kernel_size=(1,), stride=(1,))\n",
       "    )\n",
       "    (3): Sequential(\n",
       "      (0): Conv1d(1152, 192, kernel_size=(1,), stride=(1,), bias=False)\n",
       "      (1): BatchNorm1d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "  )\n",
       "  (15): Sequential(\n",
       "    (0): Sequential(\n",
       "      (0): Sequential(\n",
       "        (0): Conv1d(192, 1152, kernel_size=(1,), stride=(1,), bias=False)\n",
       "        (1): BatchNorm1d(1152, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (1): SiLU(inplace=True)\n",
       "    )\n",
       "    (1): Sequential(\n",
       "      (0): Sequential(\n",
       "        (0): Conv1d(1152, 1152, kernel_size=(5,), stride=(1,), padding=(2,), bias=False)\n",
       "        (1): BatchNorm1d(1152, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (1): SiLU(inplace=True)\n",
       "    )\n",
       "    (2): Sequential(\n",
       "      (0): Conv1d(1152, 48, kernel_size=(1,), stride=(1,))\n",
       "      (1): SiLU()\n",
       "      (2): Conv1d(48, 1152, kernel_size=(1,), stride=(1,))\n",
       "    )\n",
       "    (3): Sequential(\n",
       "      (0): Conv1d(1152, 192, kernel_size=(1,), stride=(1,), bias=False)\n",
       "      (1): BatchNorm1d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "  )\n",
       "  (16): Sequential(\n",
       "    (0): Sequential(\n",
       "      (0): Sequential(\n",
       "        (0): Conv1d(192, 1152, kernel_size=(1,), stride=(1,), bias=False)\n",
       "        (1): BatchNorm1d(1152, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (1): SiLU(inplace=True)\n",
       "    )\n",
       "    (1): Sequential(\n",
       "      (0): Sequential(\n",
       "        (0): Conv1d(1152, 1152, kernel_size=(3,), stride=(1,), padding=(1,), bias=False)\n",
       "        (1): BatchNorm1d(1152, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (1): SiLU(inplace=True)\n",
       "    )\n",
       "    (2): Sequential(\n",
       "      (0): Conv1d(1152, 48, kernel_size=(1,), stride=(1,))\n",
       "      (1): SiLU()\n",
       "      (2): Conv1d(48, 1152, kernel_size=(1,), stride=(1,))\n",
       "    )\n",
       "    (3): Sequential(\n",
       "      (0): Conv1d(1152, 320, kernel_size=(1,), stride=(1,), bias=False)\n",
       "      (1): BatchNorm1d(320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "  )\n",
       "  (17): Sequential(\n",
       "    (0): Sequential(\n",
       "      (0): Sequential(\n",
       "        (0): Conv1d(320, 512, kernel_size=(1,), stride=(1,), bias=False)\n",
       "        (1): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (1): SiLU(inplace=True)\n",
       "    )\n",
       "    (1): AdaptiveAvgPool1d(output_size=200)\n",
       "    (2): Linear(in_features=200, out_features=1, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "effnet_b0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a7c1c10-7cf4-47d9-a59d-af5bacc17270",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "zenv",
   "language": "python",
   "name": "zenv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
