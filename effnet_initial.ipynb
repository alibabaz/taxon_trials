{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "91ccd3df-4734-4713-a8de-57b633a31b84",
   "metadata": {},
   "source": [
    "Based off of the efficientnet in Timm: https://github.com/rwightman/pytorch-image-models/blob/master/timm/models/efficientnet.py  we will reporpose this architecture for our use with 1-dimension sequence data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "40d72063-2687-4a72-a486-a1470da92a57",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "import h5py\n",
    "from exabiome.nn.loader import read_dataset, LazySeqDataset\n",
    "import argparse\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "aec0806b-6c0e-4b2d-9c15-57e6029bc5de",
   "metadata": {},
   "outputs": [],
   "source": [
    "path = '/global/homes/a/azaidi/ar122_r202.toy.input.h5'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d3906eea-a618-4a41-912e-f7044712abd3",
   "metadata": {},
   "outputs": [],
   "source": [
    "hparams = argparse.Namespace(**{'load': False,\n",
    "                            'window': 4096,\n",
    "                            'step': 4096,\n",
    "                             'classify': True,\n",
    "                               'tgt_tax_lvl': \"phylum\",\n",
    "                               'fwd_only': True})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d8c9e7b7-9f59-4008-b52c-b796e5c6389e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "19010"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chunks = LazySeqDataset(hparams, path=path, keep_open=True)\n",
    "len(chunks)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67741a8b-e7eb-4f79-9ddf-430b64a241d5",
   "metadata": {},
   "source": [
    "Let's use a function to use a transform for the x value (for padding) instead of having that logic in the dataset class "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "65b84139-7b46-4d6b-84c8-a410c9ae23b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def old_pad_seq(seq):\n",
    "    if(len(seq) < 4096):\n",
    "        padded = torch.zeros(4096)\n",
    "        padded[:len(seq)] = seq\n",
    "        return padded\n",
    "    else:\n",
    "        return seq"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81916c9c-98c7-407f-9a9b-8c6fd6e43785",
   "metadata": {},
   "source": [
    "That's not a very clean transform fxn above, but w/e -- Pytorch uses lambda functions in their docs anyways ;)\n",
    "\n",
    "Pytorch has a F.pad function that would do the work for -- this is causing issues below, we'll proceed with the old_pad_seq fxn for now"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "6295321e-ae4f-41de-a91f-a8ef14bca46f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def pad_seq(seq):\n",
    "    if(len(seq) < 4096):\n",
    "        return F.pad(seq, (0, 4096-len(seq))).long()\n",
    "    else:\n",
    "        return seq"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b46170d5-ee21-4f5f-8f91-ab32d1ad603d",
   "metadata": {},
   "source": [
    "We also don't want to do the unsqueezing at the batch level everytime it's called -- let's do it here :)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "876f2f59-8585-4a5e-a30e-c3bd6d62a96a",
   "metadata": {},
   "outputs": [],
   "source": [
    "class taxon_ds(Dataset):\n",
    "    def __init__(self, chunks, transform=None):\n",
    "        self.chunks = chunks\n",
    "        self.transform = transform\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.chunks)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        x = chunks[idx][1]\n",
    "        if self.transform:\n",
    "            x = self.transform(x)\n",
    "        y = chunks[idx][2]\n",
    "        return (x.unsqueeze(0), y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "cad2b8dd-d5a0-41c5-8d74-e5bcb53b65b3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 5 µs, sys: 0 ns, total: 5 µs\n",
      "Wall time: 10.3 µs\n"
     ]
    }
   ],
   "source": [
    "%time\n",
    "ds = taxon_ds(chunks, pad_seq)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "67c95aeb-f936-485d-9dea-799b7729f0a0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 3 µs, sys: 0 ns, total: 3 µs\n",
      "Wall time: 5.48 µs\n"
     ]
    }
   ],
   "source": [
    "%time\n",
    "ds = taxon_ds(chunks, old_pad_seq)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6ad1e22-4df0-443b-9c0f-b8c57e3ae2d6",
   "metadata": {},
   "source": [
    "If you keep running the cells above, you can see that sometimes the old padding function is faster\n",
    "\n",
    "F.pad: https://pytorch.org/docs/stable/nn.functional.html#pad has a note about nondeterministic behavior in a backward pass -- not sure if that's relevant, but these are the tensors that will eventually make it into training loop, so maybe something to come back to"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "id": "bc6fa684-ea9d-46cf-909b-a67fb6982352",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([1180]), torch.Size([1, 4096]))"
      ]
     },
     "execution_count": 114,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#the second sample in chunks is not 4096 in length, let's confirm here that our padding is working\n",
    "chunks[2][1].shape, ds[2][0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "id": "25c2caa2-3655-4d1b-a2da-463d04a068f7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1189"
      ]
     },
     "execution_count": 115,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dl = DataLoader(ds, batch_size=16, shuffle=True)\n",
    "len(dl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "id": "7d48d4f1-1c88-473a-8fd6-3f08ae71fbec",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([16, 1, 4096]), torch.Size([16]))"
      ]
     },
     "execution_count": 116,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch = next(iter(dl))\n",
    "batch[0].shape, batch[1].shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6bd2b07-4f2e-4b95-af80-875499b93a54",
   "metadata": {},
   "source": [
    "# An Efficientnet has basically three parts: \n",
    "**(0) Base (Feet) --> (1) Body --> (2) Head**\n",
    "\n",
    "Within these three parts -- we are **mainly** only using three tools/units of computation:\n",
    "\n",
    "(0) Conv1d: https://pytorch.org/docs/stable/generated/torch.nn.Conv1d.html <br>\n",
    "(1) BatchNorm1d: https://pytorch.org/docs/stable/generated/torch.nn.BatchNorm1d.html <br>\n",
    "(2) SiLU: https://pytorch.org/docs/stable/generated/torch.nn.SiLU.html <br>\n",
    "\n",
    "*There are a few other items that are added as well, that we will see below\n",
    "\n",
    "<br>**Base** (feet):<br>\n",
    "0) Conv1d --> 1) BatchNorm1d --> 2) SiLU\n",
    "\n",
    "**Head**: <br>\n",
    "(0) Conv1d --> (1) BatchNorm1d --> (2) SiLU --> (3) SelectAdaptivePool1d --> (4) Linear\n",
    "\n",
    "*the base & head are relatively straightforward -- we'll implement both below:*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "e8cc33f7-1ad6-41d0-8a81-06a8aed67f81",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_base_layer(in_chans=1, out_chans=32, ks=3, stride=2):\n",
    "    return nn.Sequential(\n",
    "        nn.Conv1d(in_channels= in_chans, out_channels= out_chans, \n",
    "                  kernel_size= ks, stride= stride),\n",
    "        nn.BatchNorm1d(num_features = out_chans),\n",
    "        nn.SiLU())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "50203182-f15f-4f4f-83b2-e1a94e698908",
   "metadata": {},
   "outputs": [],
   "source": [
    "#uncomment to confirm that this produces what was expected\n",
    "#get_base_layer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "9a97cca5-ca2b-4b03-9c68-c53ea5388f49",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_head_layer(in_chans=1, out_chans=32, ks=3, stride=2,\n",
    "              avg_out_feats=10, lin_out_feats=1):\n",
    "    return nn.Sequential(\n",
    "        nn.Conv1d(in_channels= in_chans, out_channels= out_chans, \n",
    "                  kernel_size= ks, stride= stride),\n",
    "        nn.BatchNorm1d(num_features = out_chans),\n",
    "        nn.SiLU(),\n",
    "        nn.AdaptiveAvgPool1d(output_size=avg_out_feats),\n",
    "        nn.Linear(in_features=avg_out_feats, out_features=lin_out_feats))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d55b9a2b-8942-456a-b0b1-85cb08c8139a",
   "metadata": {},
   "source": [
    "**The parameters chosen above are arbitrary for the time being**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "f5091ec3-9d64-46a2-aca7-95b8bde77850",
   "metadata": {},
   "outputs": [],
   "source": [
    "#uncomment to confirm that this produces what was expected\n",
    "#get_head_layer()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8b3c42d-549d-4769-91b4-a98a2daef516",
   "metadata": {},
   "source": [
    "**Body**:<br>\n",
    "(0) DepthwiseSeparableConv <br>\n",
    "(1) InvertedResidual (two in a row) <br>\n",
    "(2) InvertedResidual (two in a row) <br>\n",
    "(3) InvertedResidual (three in a row) <br>\n",
    "(4) InvertedResidual (three in a row) <br>\n",
    "(5) InvertedResidual (three in a row) <br>\n",
    "(6) InvertedResidual (one) <br>\n",
    "\n",
    "*ok so what are these layers in the body?*"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e79f13e8-bf77-4a76-89c1-2002f67cbdf4",
   "metadata": {},
   "source": [
    "# DepthwiseSeperable:\n",
    "(0) Conv1d <br>\n",
    "(1) BatchNorm1d <br>\n",
    "(2) SiLU <br>\n",
    "(3) **Squeeze Excite**<br>\n",
    "(4) Conv1d <br>\n",
    "(5) BatchNorm1d <br>\n",
    "(6) Identity <br>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "469d5b6d-fb8b-4719-bf06-71495d5d23cc",
   "metadata": {},
   "source": [
    "# InvertedResidual:\n",
    "(0) Conv1d <br>\n",
    "(1) BatchNorm1d <br>\n",
    "(2) SiLU <br>\n",
    "(3) Conv1d <br>\n",
    "(4) BatchNorm1d <br>\n",
    "(5) SiLU <br>\n",
    "(6) **Squeeze Excite**<br>\n",
    "(7) Conv1d <br>\n",
    "(8) BatchNorm1d <br>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99a8dc6e-f5fc-495c-bd1e-d5a0ee437d50",
   "metadata": {},
   "source": [
    "**\"Squeeze Excite\" = Conv1d --> SiLU --> Conv1d**\n",
    "\n",
    "Let's first define our squeeze excite function -- since we have two conv layers, let's use tuples for our parameters for now"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "d11342f6-6228-42a7-8501-d456ce10f0d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_sq_ex(in_ch= (1,1), out_ch= (2,2), ks= (2,2), stride= (2,2)):\n",
    "    return nn.Sequential(\n",
    "        nn.Conv1d(in_channels= in_ch[0], out_channels= out_ch[0], \n",
    "                  kernel_size= ks[0], stride= stride[0]),\n",
    "        nn.SiLU(),\n",
    "        nn.Conv1d(in_channels= in_ch[1], out_channels= out_ch[1], \n",
    "                  kernel_size= ks[1], stride= stride[1])\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "20077310-ba2b-4795-8e49-9d4dfead9ec2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Sequential(\n",
       "  (0): Conv1d(1, 2, kernel_size=(2,), stride=(2,))\n",
       "  (1): SiLU()\n",
       "  (2): Conv1d(1, 2, kernel_size=(2,), stride=(2,))\n",
       ")"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#uncomment to confirm the above function works\n",
    "get_sq_ex()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e8d9cf4-3357-4e6e-a33a-89b172c911fb",
   "metadata": {},
   "source": [
    "We also have a ton of Conv1d --> BatchNorm1d sets, let's define a function to pull that out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "92b25330-1cd0-46cf-a4a2-d6abf93a7c9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_conv_bn(in_ch=1, out_ch=2, ks=2, stride=2):\n",
    "    return nn.Sequential(\n",
    "        nn.Conv1d(in_channels = in_ch, out_channels = out_ch,\n",
    "                 kernel_size = ks, stride = stride),\n",
    "        nn.BatchNorm1d(num_features = out_ch)\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "a2e97b66-1433-4833-8a74-b5cbb4c4bb70",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Sequential(\n",
       "  (0): Conv1d(1, 2, kernel_size=(2,), stride=(2,))\n",
       "  (1): BatchNorm1d(2, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       ")"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#uncomment to confirm the above function works\n",
    "get_conv_bn()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91bffe8f-0a59-40aa-aec9-d684b46e9edc",
   "metadata": {},
   "source": [
    "The above functions have simplified our work to produce the desired layers -- we have everything we need to create both the layer types in our models body\n",
    "\n",
    "**DepthwiseSeperable**: <br>\n",
    "(0) get_conv_bn <br>\n",
    "(1) SiLU <br>\n",
    "(2) get_sq_ex <br>\n",
    "(3) get_conv_bn <br>\n",
    "(4) Identity <br>\n",
    "\n",
    "**InvertedResidual**: <br>\n",
    "(0) get_conv_bn <br>\n",
    "(1) SiLU <br>\n",
    "(2) get_conv_bn <br>\n",
    "(3) SiLU <br>\n",
    "(4) get_sq_ex <br>\n",
    "(5) get_conv_bn <br>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "311bdd51-a50b-46b0-8014-21a79851dac9",
   "metadata": {},
   "source": [
    "A squeeze-excite unit compresses the number of channels down and then expands it back to the original amount"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "id": "babadb41-f254-4491-9577-3325ba7a1eae",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_dep_sep(in_ch, out_ch, ks=3, reduction=6):\n",
    "    return nn.Sequential(\n",
    "        get_conv_bn(in_ch=in_ch, out_ch=in_ch*2, ks=ks),\n",
    "        nn.SiLU(),\n",
    "        get_sq_ex(in_ch=(in_ch*2, reduction), \n",
    "                  out_ch=(reduction, in_ch*2)),\n",
    "        get_conv_bn(in_ch=in_ch*2, out_ch=out_ch),\n",
    "        nn.Identity()\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "id": "b738503e-18f6-49b5-bc0b-f2f05b38ca6f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([16, 16, 127])"
      ]
     },
     "execution_count": 145,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#let's just make sure things are moving forward with our depthwise seperable layer\n",
    "nn.Sequential(\n",
    "    get_base_layer(),\n",
    "    get_dep_sep(32, 16)\n",
    ")(batch[0]).shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8280f8fb-8f91-4c6f-b8c2-0dc9ce6267bc",
   "metadata": {},
   "source": [
    "In order to preserve some semblance of clarity and avoid making this notebook too long, we will only add a single inverted residual layer and confirm that we can pass our data through this (An EfficientNet_b0 has 14 inverted residual layers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "id": "5e324489-bf4e-4c80-9846-741d5cd426a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_inv_res(in_ch, out_ch, ks=3, reduction=4):\n",
    "    return nn.Sequential(\n",
    "        get_conv_bn(in_ch=in_ch, out_ch=in_ch*4, ks=1),\n",
    "        nn.SiLU(),\n",
    "        get_conv_bn(in_ch=in_ch*4, out_ch=in_ch*4, ks=3),\n",
    "        get_sq_ex(in_ch=(in_ch*4, reduction),\n",
    "                 out_ch=(reduction, in_ch*4)),\n",
    "        get_conv_bn(in_ch=in_ch*4, out_ch=out_ch)\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "id": "ed14f6e5-7660-4c97-9529-d9c2fd692986",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([16, 12, 3])"
      ]
     },
     "execution_count": 150,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nn.Sequential(\n",
    "    get_base_layer(),\n",
    "    get_dep_sep(32,16),\n",
    "    get_inv_res(16, 12)\n",
    ")(batch[0]).shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "349a561c-e4e0-48f3-b672-62388e2e3e93",
   "metadata": {},
   "source": [
    "Looks like things are working! :)\n",
    "\n",
    "Obviously a better encoding needs to be put into place in order for the model to sensibly parse the data (additional inverted residiaul layers) but we have the building blocks to refactor this and make the model creation much easier! \n",
    "\n",
    "*since our activation function (SiLU) occurs only after the get_conv_bn call, we could actually include this into our definition of that function and simply add a parameter + some logic to determine if we want to append an activation to that sequential layer group. This will be added in the refactored notebook*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06c8fd18-479d-485a-a7ae-4e0a40b66f4e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "zenv",
   "language": "python",
   "name": "zenv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
